{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cf3512e-0d86-43a7-9e01-ebe0fe6404a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-13T14:19:29.122469Z",
     "iopub.status.busy": "2025-09-13T14:19:29.121827Z",
     "iopub.status.idle": "2025-09-13T14:19:30.091284Z",
     "shell.execute_reply": "2025-09-13T14:19:30.090318Z",
     "shell.execute_reply.started": "2025-09-13T14:19:29.122441Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'PCB-Diffusion-AD'...\n",
      "remote: Enumerating objects: 58, done.\u001b[K\n",
      "remote: Counting objects: 100% (58/58), done.\u001b[K\n",
      "remote: Compressing objects: 100% (35/35), done.\u001b[K\n",
      "remote: Total 58 (delta 26), reused 51 (delta 19), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (58/58), 41.35 KiB | 1.97 MiB/s, done.\n",
      "Resolving deltas: 100% (26/26), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/nguyenduchuyiu/PCB-Diffusion-AD.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cf4d8fa-14dd-40d2-8426-f5c4600b3491",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-13T14:19:30.092708Z",
     "iopub.status.busy": "2025-09-13T14:19:30.092445Z",
     "iopub.status.idle": "2025-09-13T14:19:30.099519Z",
     "shell.execute_reply": "2025-09-13T14:19:30.098745Z",
     "shell.execute_reply.started": "2025-09-13T14:19:30.092653Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/PCB-Diffusion-AD\n"
     ]
    }
   ],
   "source": [
    "%cd PCB-Diffusion-AD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0356f7ac-03aa-4169-86b9-3f7d6305f33a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-13T14:19:30.101313Z",
     "iopub.status.busy": "2025-09-13T14:19:30.101108Z",
     "iopub.status.idle": "2025-09-13T14:19:35.775400Z",
     "shell.execute_reply": "2025-09-13T14:19:35.774715Z",
     "shell.execute_reply.started": "2025-09-13T14:19:30.101297Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imgaug\n",
      "  Downloading imgaug-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from imgaug) (1.17.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.11/dist-packages (from imgaug) (1.26.4)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from imgaug) (1.15.3)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from imgaug) (11.2.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from imgaug) (3.7.2)\n",
      "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.11/dist-packages (from imgaug) (0.25.2)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from imgaug) (4.11.0.86)\n",
      "Requirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (from imgaug) (2.37.0)\n",
      "Requirement already satisfied: Shapely in /usr/local/lib/python3.11/dist-packages (from imgaug) (2.1.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.15->imgaug) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.15->imgaug) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.15->imgaug) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.15->imgaug) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.15->imgaug) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.15->imgaug) (2.4.1)\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.14.2->imgaug) (3.5)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.14.2->imgaug) (2025.6.11)\n",
      "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.14.2->imgaug) (25.0)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.14.2->imgaug) (0.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug) (1.4.8)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug) (2.9.0.post0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.15->imgaug) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.15->imgaug) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.15->imgaug) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.15->imgaug) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.15->imgaug) (2024.2.0)\n",
      "Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m948.0/948.0 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: imgaug\n",
      "Successfully installed imgaug-0.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install imgaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2e51a2-52b3-4e44-9778-b682ac361b14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-13T14:19:35.776712Z",
     "iopub.status.busy": "2025-09-13T14:19:35.776412Z",
     "iopub.status.idle": "2025-09-13T14:19:35.782931Z",
     "shell.execute_reply": "2025-09-13T14:19:35.782210Z",
     "shell.execute_reply.started": "2025-09-13T14:19:35.776675Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting args/args1.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile args/args1.json\n",
    "{\n",
    "  \"img_size\": [256,256],\n",
    "  \"Batch_Size\": 4,\n",
    "  \"EPOCHS\": 3000,\n",
    "  \"T\": 1000,\n",
    "  \"base_channels\": 128,\n",
    "  \"beta_schedule\": \"linear\",\n",
    "  \"loss_type\": \"l2\",\n",
    "  \"diffusion_lr\": 1e-4,\n",
    "  \"seg_lr\": 1e-5,\n",
    "  \"random_slice\": true,\n",
    "  \"weight_decay\": 0.0,\n",
    "  \"save_imgs\":true,\n",
    "  \"save_vids\":false, \n",
    "  \"dropout\":0,\n",
    "  \"attention_resolutions\":\"32,16,8\",\n",
    "  \"num_heads\":4,\n",
    "  \"num_head_channels\":-1,\n",
    "  \"noise_fn\":\"gauss\",\n",
    "  \"channels\":3,\n",
    "  \"data_name\":\"RealIAD\",\n",
    "  \"data_root_path\":\"/kaggle/input/pcb-dataset\",\n",
    "  \"anomaly_source_path\":\"/kaggle/input/pcb-dataset/dtd\",\n",
    "  \"noisier_t_range\":600,\n",
    "  \"less_t_range\":300,\n",
    "  \"condition_w\":1,\n",
    "  \"eval_normal_t\":200,\n",
    "  \"eval_noisier_t\":400,\n",
    "  \"output_path\":\"outputs\",\n",
    "  \"gradient_accumulation_steps\": 4,\n",
    "  \"use_mixed_precision\": true\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fb86013-2952-4448-be8f-d50a5bfe4806",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-13T14:19:35.784029Z",
     "iopub.status.busy": "2025-09-13T14:19:35.783804Z",
     "iopub.status.idle": "2025-09-13T14:31:39.194312Z",
     "shell.execute_reply": "2025-09-13T14:31:39.193679Z",
     "shell.execute_reply.started": "2025-09-13T14:19:35.784003Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs: 2\n",
      "Using 2 GPUs for training\n",
      "class PCB5\n",
      "args1.json defaultdict(<class 'str'>, {'img_size': [256, 256], 'Batch_Size': 4, 'EPOCHS': 1, 'T': 1000, 'base_channels': 128, 'beta_schedule': 'linear', 'loss_type': 'l2', 'diffusion_lr': 0.0001, 'seg_lr': 1e-05, 'random_slice': True, 'weight_decay': 0.0, 'save_imgs': True, 'save_vids': False, 'dropout': 0, 'attention_resolutions': '32,16,8', 'num_heads': 4, 'num_head_channels': -1, 'noise_fn': 'gauss', 'channels': 3, 'data_name': 'RealIAD', 'data_root_path': '/kaggle/input/pcb-dataset', 'anomaly_source_path': '/kaggle/input/pcb-dataset/dtd', 'noisier_t_range': 600, 'less_t_range': 300, 'condition_w': 1, 'eval_normal_t': 200, 'eval_noisier_t': 400, 'output_path': 'outputs', 'gradient_accumulation_steps': 4, 'use_mixed_precision': True, 'arg_num': '1'})\n",
      "Batch size configuration:\n",
      "  - Base batch size: 4\n",
      "  - DataLoader batch size: 4 (Multi-GPU)\n",
      "  - Gradient accumulation steps: 4\n",
      "  - Total effective batch size: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "/kaggle/working/PCB-Diffusion-AD/train.py:115: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler() if use_mixed_precision else None\n",
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping models with DataParallel for 2 GPUs\n",
      "Model Parameters:\n",
      "  - UNet Model: 131,654,403 parameters\n",
      "  - Segmentation Model: 28,373,569 parameters\n",
      "  - Total Trainable Parameters: 160,027,972 parameters\n",
      "  - Memory (approx): 610.5 MB (FP32)\n",
      "Mixed Precision (FP16): Enabled\n",
      "Gradient Accumulation Steps: 4\n",
      "Effective Batch Size: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:0, Train loss: 336.367: 100%|██████████| 493/493 [11:47<00:00,  1.43s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch, gc\n",
    "\n",
    "gc.collect() \n",
    "torch.cuda.empty_cache()  \n",
    "torch.cuda.ipc_collect()  \n",
    "\n",
    "from random import seed\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from models.Recon_subnetwork import UNetModel, update_ema_params\n",
    "from models.Seg_subnetwork import SegmentationSubNetwork\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from data.dataset_beta_thresh import RealIADTrainDataset, RealIADTestDataset\n",
    "from math import exp\n",
    "import torch.nn.functional as F\n",
    "from models.DDPM import GaussianDiffusionModel, get_beta_schedule\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from skimage.measure import label, regionprops\n",
    "from sklearn.metrics import roc_auc_score,auc,average_precision_score\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from train import defaultdict_from_json, train\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Check for multiple GPUs\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(f\"Number of available GPUs: {num_gpus}\")\n",
    "if num_gpus > 1:\n",
    "    print(f\"Using {num_gpus} GPUs for training\")\n",
    "elif num_gpus == 1:\n",
    "    print(\"Using single GPU for training\")\n",
    "else:\n",
    "    print(\"Using CPU for training\")\n",
    "\n",
    "# read file from argument\n",
    "file = \"args1.json\"\n",
    "# load the json args\n",
    "with open(f'./args/{file}', 'r') as f:\n",
    "    args = json.load(f)\n",
    "args['arg_num'] = file[4:-5]\n",
    "args = defaultdict_from_json(args)\n",
    "\n",
    "\n",
    "real_iad_classes = os.listdir(os.path.join(args[\"data_root_path\"], args['data_name']))\n",
    "\n",
    "for sub_class in real_iad_classes:   \n",
    "    print(\"class\", sub_class)\n",
    "    \n",
    "    subclass_path = os.path.join(args[\"data_root_path\"], args['data_name'], sub_class)\n",
    "    \n",
    "    training_dataset = RealIADTrainDataset(\n",
    "        subclass_path, sub_class, img_size=args[\"img_size\"], args=args\n",
    "    )\n",
    "    testing_dataset = RealIADTestDataset(\n",
    "        subclass_path, sub_class, img_size=args[\"img_size\"]\n",
    "    )\n",
    "    class_type=args['data_name']\n",
    "    \n",
    "\n",
    "    print(file, args)     \n",
    "\n",
    "    data_len = len(testing_dataset)\n",
    "    \n",
    "    # Calculate effective batch size considering multi-GPU and gradient accumulation\n",
    "    base_batch_size = args['Batch_Size']\n",
    "    gradient_accumulation_steps = args.get('gradient_accumulation_steps', 1)\n",
    "    \n",
    "    # For DataLoader, we use the base batch size\n",
    "    dataloader_batch_size = base_batch_size\n",
    "    \n",
    "    # Total effective batch size\n",
    "    total_effective_batch_size = dataloader_batch_size * gradient_accumulation_steps\n",
    "    \n",
    "    print(f\"Batch size configuration:\")\n",
    "    print(f\"  - Base batch size: {base_batch_size}\")\n",
    "    print(f\"  - DataLoader batch size: {dataloader_batch_size} ({'Multi-GPU' if num_gpus > 1 else 'Single-GPU'})\")\n",
    "    print(f\"  - Gradient accumulation steps: {gradient_accumulation_steps}\")\n",
    "    print(f\"  - Total effective batch size: {total_effective_batch_size}\")\n",
    "    \n",
    "    training_dataset_loader = DataLoader(training_dataset, batch_size=dataloader_batch_size,shuffle=True,num_workers=8,pin_memory=True,drop_last=True)\n",
    "    test_loader = DataLoader(testing_dataset, batch_size=1,shuffle=False, num_workers=4)\n",
    "\n",
    "    # make arg specific directories\n",
    "    for i in [f'{args[\"output_path\"]}/model/diff-params-ARGS={args[\"arg_num\"]}/{sub_class}',\n",
    "            f'{args[\"output_path\"]}/diffusion-training-images/ARGS={args[\"arg_num\"]}/{sub_class}',\n",
    "             f'{args[\"output_path\"]}/metrics/ARGS={args[\"arg_num\"]}/{sub_class}']:\n",
    "        try:\n",
    "            os.makedirs(i)\n",
    "        except OSError:\n",
    "            pass\n",
    "\n",
    "\n",
    "    train(training_dataset_loader, test_loader, args, data_len,sub_class,class_type,device, num_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db00573-c272-4367-abb9-4d9dae8d09e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-13T14:31:39.195529Z",
     "iopub.status.busy": "2025-09-13T14:31:39.195332Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs: 2\n",
      "Using 2 GPUs for evaluation\n",
      "checkpoint outputs/model/diff-params-ARGS=1/PCB5/params-best.pt\n",
      "Checkpoint best not found for class PCB5, skipping.\n",
      "checkpoint outputs/model/diff-params-ARGS=1/PCB5/params-last.pt\n",
      "args1\n",
      "class PCB5\n",
      "Wrapping models with DataParallel for 2 GPUs\n",
      "EPOCH: 1\n",
      "data_len 2782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 1166/2782 [19:36<31:19,  1.16s/it]  "
     ]
    }
   ],
   "source": [
    "import torch, gc\n",
    "\n",
    "gc.collect() \n",
    "torch.cuda.empty_cache()  \n",
    "torch.cuda.ipc_collect()  \n",
    "from eval import testing, load_parameters, defaultdict_from_json\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Check for multiple GPUs\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(f\"Number of available GPUs: {num_gpus}\")\n",
    "if num_gpus > 1:\n",
    "    print(f\"Using {num_gpus} GPUs for evaluation\")\n",
    "elif num_gpus == 1:\n",
    "    print(\"Using single GPU for evaluation\")\n",
    "else:\n",
    "    print(\"Using CPU for evaluation\")\n",
    "file = \"args1.json\"\n",
    "# load the json args\n",
    "with open(f'./args/{file}', 'r') as f:\n",
    "    args = json.load(f)\n",
    "args['arg_num'] = file[4:-5]\n",
    "args = defaultdict_from_json(args)\n",
    "real_iad_classes = os.listdir(os.path.join(args[\"data_root_path\"], args['data_name']))\n",
    "\n",
    "current_classes = real_iad_classes\n",
    "checkpoint_types = ['best', 'last']\n",
    "\n",
    "for sub_class in current_classes:\n",
    "    for checkpoint_type in checkpoint_types:\n",
    "        try:\n",
    "            args, output = load_parameters(device, sub_class, checkpoint_type)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Checkpoint {checkpoint_type} not found for class {sub_class}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"args{args['arg_num']}\")\n",
    "        print(\"class\", sub_class)\n",
    "        \n",
    "        in_channels = args[\"channels\"]\n",
    "\n",
    "        unet_model = UNetModel(args['img_size'][0], args['base_channels'], channel_mults=args['channel_mults'], dropout=args[\n",
    "                    \"dropout\"], n_heads=args[\"num_heads\"], n_head_channels=args[\"num_head_channels\"],\n",
    "                in_channels=in_channels\n",
    "                ).to(device)\n",
    "\n",
    "        seg_model = SegmentationSubNetwork(in_channels=6, out_channels=1).to(device)\n",
    "\n",
    "        # Load model states\n",
    "        unet_model.load_state_dict(output[\"unet_model_state_dict\"])\n",
    "        unet_model.to(device)\n",
    "        \n",
    "        seg_model.load_state_dict(output[\"seg_model_state_dict\"])\n",
    "        seg_model.to(device)\n",
    "        \n",
    "        # Enable multi-GPU for evaluation if available\n",
    "        if num_gpus > 1:\n",
    "            print(f\"Wrapping models with DataParallel for {num_gpus} GPUs\")\n",
    "            unet_model = torch.nn.DataParallel(unet_model)\n",
    "            seg_model = torch.nn.DataParallel(seg_model)\n",
    "        \n",
    "        unet_model.eval()\n",
    "        seg_model.eval()\n",
    "\n",
    "        print(\"EPOCH:\", output['n_epoch'])\n",
    "\n",
    "        testing_dataset = RealIADTestDataset(\n",
    "            args[\"data_root_path\"], sub_class, img_size=args[\"img_size\"]\n",
    "        )\n",
    "        class_type = args['data_name']\n",
    "                \n",
    "        data_len = len(testing_dataset) \n",
    "        test_loader = DataLoader(testing_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "        # make arg specific directories\n",
    "        for i in [f'{args[\"output_path\"]}/metrics/ARGS={args[\"arg_num\"]}/{sub_class}']:\n",
    "            try:\n",
    "                os.makedirs(i)\n",
    "            except OSError:\n",
    "                pass\n",
    "\n",
    "        testing(test_loader, args, unet_model, seg_model, data_len, sub_class, class_type, checkpoint_type, device)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8259797,
     "sourceId": 13044152,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
